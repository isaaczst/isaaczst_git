-
- 1 文章摘要
	- 流形优化在计算和应用数学、科学工程、机器学习、物理和化学等领域中有着广泛应用  。
	- 它的主要困难之一通常来自于流形约束的非凸性。
	- 通过利用流形的几何结构，一大类约束优化问题可以视为流形上的无约束优化问题。
	- 从这个角度出发，人们研究了流形优化的内蕴结构、最优性条件和数值算法。
	- 本文也介绍了流形优化理论的一些最新进展。
- 2 流形优化简介
	- 流形优化的研究对象是一类带有流形约束的优化问题：
-
- 其中[公式]是黎曼流形，[公式]是[公式]上的实值函数，[公式]可以是非光滑的。如果除流形约束以外还有其他约束，我们可以在[公式]中添加这些附加约束的可行集的指标函数。流形优化已广泛应用于计算和应用数学，统计，机器学习，数据科学，材料科学等领域。 流形约束的存在是算法设计和理论分析的主要困难之一。 本文分三个部分分别介绍了流形优化的各种应用、流形优化的最新算法和一些基于流形优化的理论结果。
- 3 流形优化的应用
	- 流形优化在[公式]-调和流理论，最大割问题，低秩相关系数矩阵估计，相位恢复，玻色-爱因斯坦凝聚，低温电子显微镜（cryo-EM）成像，线性特征值问题， 电子结构计算中的非线性特征值问题，组合优化，深度学习等方面有着广泛的应用。
	- 其主要思想是将原问题转化为流形上的优化问题，从而利用流形优化的算法，达到简化计算和高效求解的目的。
- 3.1 P-调和流
	- 图1 人脑与单位球之间的共形映射
	- [公式]-调和流被用于彩色图像恢复和医学图像分析。在医学图像分析中，不规则的人脑图片的信息很复杂。但通过共形映射将人脑映射到单位球体，就可以利用单位球的简单参数表示，实现高维向低维的转化。
- 3.2 最大割问题
	- 最大割问题是指将加权图的顶点分割成两个非空集合使横跨两个集合的所有边上的权重之和最大。由于最大割问题是NP难问题，一种常见的半定规划松弛问题是：
	- [公式]
	- 这里C是图拉普拉斯矩阵。如果做矩阵分解
	- [公式]
	- 则半定规划问题转化为：
	- [公式]
	- 这是一个多球约束优化问题。
- 3.3 K-均值聚类
	- K-均值聚类是数据挖掘中的一类常见的无监督学习问题。其问题定义如下：给定n个数据点图片: [公式]其中每个数据点都是[公式]维向量，则k-均值将它们划分为[公式]个簇[公式]，使簇内平方和最小化。 相应的数学形式为：
	- [公式]
	- 这里[公式]为第[公式]个聚类的中心。该问题可以等价的表示成：
	- [公式]
	- 这里[公式]，则该问题是在Stiefel流形上具有线性约束和非负约束的最小化问题。
- 3.4 批量标准化
	- 批量标准化是深度神经网络中非常流行的一个技巧。
	- 它通过标准化每个神经元的输入避免内部协方差平移。
	- 其对应的系数矩阵构成的空间可以看成是一个黎曼流形。
	- 对于一个深度神经网络，批量标准化通常会在非线性激活函数之前对输入进入处理。
	- 记[公式]和[公式]分别为上一层的输出和当前神经元的参数向量，对[公式]的批量标准化可以写成
	- [公式]
	- 其中[公式], [公式]和[公式]分别是[公式]的均值和协方差矩阵。
	- 从定义可以知道，使用批量标准化可以保证模型在使用大的学习率情况下不会爆炸或者消失，并且梯度在传播过程中对于线性收缩具有不变性。
	- 由于[公式] 对于任意的常数 c 成立，因此对于用了批量标准化的深度神经网络的优化问题可以看成 Grassmann 流形上的优化问题。
- 4 流形优化算法
	- 图2 [公式]流形上流形优化算法迭代示意图
	- 如图2所示我们这里以单位球为例来说明流形优化的算法结构。
	- 在第[公式]步迭代[公式]。
	- 根据[公式]的流形结构计算出的切空间，将[公式]（广义）投影到切空间[公式]上就可得到流形梯度[公式]。流形优化算法是在切空间中找一个下降方向[公式]（与[公式]夹角小于90度），例如梯度下降法中直接选取[公式]。以[公式]为初始点、[公式]为初始速度，我们可以计算一条测地线。下一个迭代点就从该测地线上产生。如果测地线上一点满足目标函数值的充分下降条件，我们则将其记为下一个迭代[公式]。
	- 实际中，因为测地线的计算量往往很高、甚至不可计算，人们常用的是用一个计算代价低的曲线来逼近测地线。
	- 这涉及到收缩算子(retraction)的概念，其为切空间到流形的一个映射（总是良定义并且对于完备流形其定义域可以是全切空间）。
	- 如上图所示，收缩算子[公式]将切空间中的点[公式]拉回到流形上[公式]处。
	- 如果该点满足目标函数值的充分下降条件，我们则将其记为下一步的迭代点[公式]。
	- 这里如果将收缩算子取为指数映射，那么相应的曲线就是测地线。
	- 但收缩算子不仅仅局限于指数映射，因而每步的迭代计算量可能会由于所使用收缩算子的低计算代价而大大减少。关于收缩算子的严格定义及[公式]上的各种收缩算子读者可以参考原文。
- 从一般的约束优化问题角度来看，有很多标准的算法可以求解流形优化问题。但因没有考虑流形的内蕴结构，这些算法都是在维数更高的欧式空间中来更新迭代。相对地，流形上的优化算法保证每一步的迭代点都是在维数较低的流形上，因而在实际中可能更有效。具体地，流形优化算法是将欧式空间的约束优化问题看成流形上的无约束优化问题。类似于欧式无约束优化算法，我们在当前迭代点的切空间中找一个合适的下降方向，比如负流形梯度方向、黎曼牛顿方向、拟牛顿方向和共轭梯度方向等。这里需要指出的是，在拟牛顿方向和共轭梯度方向的构造中，我们往往需要比较两个或者多个不同切空间的切向量，其做法是使用流形上的平行移动算子先将不同切空间的切向量移动到同一个切空间中，然后按照欧式空间的做法得到想要的拟牛顿或者共轭梯度方向。在当前点沿下降方向，我们可以局部定义测地线。通过沿测地线做曲线搜索使得迭代点列的函数值具有充分的下降量，我们可以得到全局收敛的梯度法、牛顿法、拟牛顿法和共轭梯度方法等等。
- 考虑到测地线 (指数映射) 的计算复杂度，人们将收缩算子的概念应用到算法设计中来，其可以看成是指数映射的逼近。 收缩算子相对于指数映射来说代价往往会低很多，同时又会保留算法快速收敛所必要的性质，因此在实际中有广泛的研究以及应用。同样地，由于平行移动算子计算复杂度一般较高，人们也提出了向量移动算子的概念，这个算子是平行移动算子的一个逼近，其计算代价往往较低，具体定义可以参考 [1]。为了保证拟牛顿法具有更好的收敛性质，收缩算子和向量移动通常需要满足某种配对条件。通过提出这两个算子之间的锁定条件以及提出了一种计算有效的向量移动算子，人们提出了更为有效的共轭梯度法和拟牛顿法格式。通过结合欧式几何与黎曼几何，文章 [2,3] 设计了流形优化免向量移动，能有效利用负曲率信息的正则化牛顿法和拟牛顿法。相关的算法的实现可以参见软件包ARNT、Manopt 和 ROPTLIB。
- 对于机器学习中的问题，其目标函数[公式]往往都是有限个函数[公式]的和的形式。对于无约束优化情形，有很多非常有效的算法，比如方差减小的随机梯度法 (SVRG)、自适应梯度法 (Adagrad)、自适应矩法 (Adam) 等等。对于带有流形约束的情形，通过利用收缩算子以及向量移动算子，这些算法都可以被很好地推广到流形上。但在实现中，出于对实际运算成本的考虑，可能有不同的版本，相关的参考文献可以参看原文章。
- 当目标函数非光滑时，人们将欧式空间中的次梯度方法推广到流形上。借助于Kurdyka-Łojasiewicz（KŁ）不等式，黎曼次梯度法收敛性可以被进一步分析。对于黎曼流形上的局部Lipschitz函数，梯度采样方法和非光滑黎曼信赖域方法也被先后提出。鉴于近似点梯度法和交替方向乘子法在凸优化问题上来的成功，一些学者通过合适的推广得到了针对流形上优化问题的版本。
- 对于流形优化算法的复杂度分析，人们给出了流形上梯度下降法以及信赖域方法的结果。类似于欧式无约束优化，流形上梯度下降法 (使用固定步长或者 Armijo 线搜索) 收敛到流形梯度范数小于[公式]至多需要[公式]步。在合适的假设条件下，黎曼信赖域方法收敛到黎曼梯度范数小于[公式]且黎曼海瑟矩阵在[公式]精度下半正定至多需要[公式]次迭代。对于流形上的三次正则化方法，人们也给出了[公式]迭代复杂度结果。