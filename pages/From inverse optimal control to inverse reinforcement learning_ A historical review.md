title:: From inverse optimal control to inverse reinforcement learning: A historical review

- https://www.sciencedirect.com/science/article/abs/pii/S1367578820300511?casa_token=oERoVHDiqJYAAAAA:vR8wKhoGU2ahycy37DiCeDikWHULFpsnI2b7ej6PaWZvUilMT-0ZnVej_3EsMze179IwdfmM_Q
- Highlights
	- Providing a historical review on inverse optimal control (IOC) and inverse reinforcement learning (IRL).
	- Providing a comparative view on IOC and IRL.
	- Categorizing the methods in IOC and IRL.
	- Explaining the most important methods of IOC and IRL in similar frameworks.
	- Discussing the challenges existing in IOC and IRL.
- Abstract
	- Inverse optimal control (IOC) is a powerful theory that addresses the inverse problems in control systems, robotics, Machine Learning (ML) and optimization taking into account the optimal manners.
	- This paper reviews the history of the IOC and Inverse Reinforcement Learning (IRL) approaches and describes the connections and differences between them to cover the research gap in the existing literature.
	- The general formulation of IOC/IRL is described and the related methods are categorized based on a hierarchical approach.
	- For this purpose, IOC methods are categorized under two classes, namely classic and modern approaches.
	- The classic IOC is typically formulated for control systems, while IRL, as a modern approach to IOC, is considered for machine learning problems.
	- Despite the presence of a handful of IOC/IRL methods, a comprehensive categorization of these methods is lacking. In addition to the IOC/IRL problems, this paper elaborates, where necessary, on other relevant concepts such as Learning from Demonstration (LfD), Imitation Learning (IL), and Behavioral Cloning. Some of the challenges encountered in the IOC/IRL problems are further discussed in this work, including ill-posedness, non-convexity, data availability, non-linearity, the curses of complexity and dimensionality, feature selection, and generalizability.